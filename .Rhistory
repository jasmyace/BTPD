checkCells[i,1] <- ifelse(substr(fileFirstName,1,5) == substr(done[i,]$FirstName,1,5),"Ok",done[i,]$Grid_ID)
}
}
#   ---- If we have a discrepancy, record what the database shows.
if(!is.na(checkCells[i,1])){
checkCells[i,3] <- paste0(done[i,]$digiUserID," -- ",done[i,]$digiPartner,collapse=" -- ")
if( done[i,]$digiDouble == 1 ){
checkCells[i,4] <- paste(paste0(fileFirstName," -- ",fileSecondName),collapse=" -- ")
} else {
checkCells[i,4] <- paste(fileFirstName,collapse=" -- ")
}
}
}
fix <- checkCells[checkCells$Grid_ID != "Ok",]
fix <- fix[order(fix$Grid_ID),]
dim(fix)
fix
getCellStatus <- function(tblDir="//lar-file-srv/Data/BTPD_2016/Analysis/Database/"){
# tblDir <- "//lar-file-srv/Data/BTPD_2016/Analysis/Database/"
assign <- read.table(paste0(tblDir,"tblCellStatus.csv"),stringsAsFactors=FALSE,sep=",",header=TRUE)
assign
}
getFolderStatus <- function(tblDir="//lar-file-srv/Data/BTPD_2016/Analysis/Database/"){
# tblDir <- "//lar-file-srv/Data/BTPD_2016/Analysis/Database/"
folder <- read.table(paste0(tblDir,"tblFolders.csv"),stringsAsFactors=FALSE,sep=",",header=TRUE)
folder
}
getRankStatus <- function(tblDir="//lar-file-srv/Data/BTPD_2016/Analysis/Database/"){
# tblDir <- "//lar-file-srv/Data/BTPD_2016/Analysis/Database/"
ranks <- read.csv(paste0(tblDir,"tblSampling.csv"),stringsAsFactors=FALSE)
ranks
}
#   ---- Need to check that all completed cells have shapefiles named after
#   ---- the person it's supposed to be, based on the userID in the assigned
#   ---- csv database.
require(rgeos)
require(maptools)
#   ---- Get the current list of who has what.
assign <- getCellStatus()
#   ---- Get users.
tblNames <- checkUser(userID=998)
#   ---- Get sampling.
tblRanks <- getRankStatus()
tblRanks <- tblRanks[order(tblRanks$sampleID),]
#   ---- Get folder structure.
tblFolders <- getFolderStatus()
done <- assign[assign$doneStatus == 1,]
done$digiEndTime <- as.POSIXlt(strptime(done$digiEndTime,format="%m/%d/%Y %H:%M"),tz="America/Denver")
done$digiStartTime <- as.POSIXlt(strptime(done$digiStartTime,format="%m/%d/%Y %H:%M"),tz="America/Denver")
done <- merge(done[,c('Grid_ID','digiPartner','doneStatus','digiDouble','digiUserID','digiPrimary','digiSecondary','digiStartTime','digiEndTime')],tblFolders[,c('Grid_ID','Range')],by=c('Grid_ID'),all.x=TRUE)
#   ---- Identify the primary digitizer.
done <- merge(done,tblNames[,c('userID','FirstName')],by.x=c('digiPrimary'),by.y=c('userID'),all.x=TRUE)
names(done)[names(done) == "FirstName"] <- "pFirstName"
#   ---- Identify the cell ranking.
done <- merge(done,tblRanks[,c('Grid_ID','sampleID')],by=c('Grid_ID'),all.x=TRUE)
#   ---- Identify the secondary digitizer.
done <- merge(done,tblNames[,c('userID','FirstName')],by.x=c('digiSecondary'),by.y=c('userID'),all.x=TRUE)
names(done)[names(done) == "FirstName"] <- "sFirstName"
#   ---- For singles, identify the person who pulled the cell.
done <- merge(done,tblNames[,c('userID','FirstName')],by.x=c('digiUserID'),by.y=c('userID'),all.x=TRUE)
names(done)[names(done) == "FirstName"] <- "FirstName"
done <- done[order(done$sampleID),]
done$time <- done$digiEndTime - done$digiStartTime
#   ---- Get the shapefiles that should be done.
done$folder <- paste0('//lar-file-srv/Data/BTPD_2016/Digitizing/',done$Range,'/',done$Grid_ID)
rownames(done) <- NULL
nCells <- nrow(done)
checkCells <- data.frame(Grid_ID=rep(NA,nrow(done)),
Double=rep(NA,nrow(done)),
DatabaseName=rep(NA,nrow(done)),
FileName=rep(NA,nrow(done)))
checkUser <- function(userID,tblDir="//lar-file-srv/Data/BTPD_2016/Analysis/Database/"){
# userID <- 102
# tblDir <- "//lar-file-srv/Data/BTPD_2016/Analysis/Database/"
#   ---- Find the user.
tblNames <- read.csv(paste0(tblDir,"tblNames.csv"))
tblNamesUserID <- tblNames[tblNames$userID == userID,]
#   ---- Check user status and active status.
if( nrow(tblNamesUserID) == 0 ){
stop("The userID submitted was not found.  Try again.",call.=FALSE)
} else if( nrow(tblNamesUserID) == 1 & (tblNamesUserID$doubleActive == 0 & tblNamesUserID$singleActive == 0) ){
stop("The userID submitted was found but is inactive.  Try again.",call.=FALSE)
}
tblNames
}
#   ---- Need to check that all completed cells have shapefiles named after
#   ---- the person it's supposed to be, based on the userID in the assigned
#   ---- csv database.
require(rgeos)
require(maptools)
#   ---- Get the current list of who has what.
assign <- getCellStatus()
#   ---- Get users.
tblNames <- checkUser(userID=998)
#   ---- Get sampling.
tblRanks <- getRankStatus()
tblRanks <- tblRanks[order(tblRanks$sampleID),]
#   ---- Get folder structure.
tblFolders <- getFolderStatus()
done <- assign[assign$doneStatus == 1,]
done$digiEndTime <- as.POSIXlt(strptime(done$digiEndTime,format="%m/%d/%Y %H:%M"),tz="America/Denver")
done$digiStartTime <- as.POSIXlt(strptime(done$digiStartTime,format="%m/%d/%Y %H:%M"),tz="America/Denver")
done <- merge(done[,c('Grid_ID','digiPartner','doneStatus','digiDouble','digiUserID','digiPrimary','digiSecondary','digiStartTime','digiEndTime')],tblFolders[,c('Grid_ID','Range')],by=c('Grid_ID'),all.x=TRUE)
#   ---- Identify the primary digitizer.
done <- merge(done,tblNames[,c('userID','FirstName')],by.x=c('digiPrimary'),by.y=c('userID'),all.x=TRUE)
names(done)[names(done) == "FirstName"] <- "pFirstName"
#   ---- Identify the cell ranking.
done <- merge(done,tblRanks[,c('Grid_ID','sampleID')],by=c('Grid_ID'),all.x=TRUE)
#   ---- Identify the secondary digitizer.
done <- merge(done,tblNames[,c('userID','FirstName')],by.x=c('digiSecondary'),by.y=c('userID'),all.x=TRUE)
names(done)[names(done) == "FirstName"] <- "sFirstName"
#   ---- For singles, identify the person who pulled the cell.
done <- merge(done,tblNames[,c('userID','FirstName')],by.x=c('digiUserID'),by.y=c('userID'),all.x=TRUE)
names(done)[names(done) == "FirstName"] <- "FirstName"
done <- done[order(done$sampleID),]
done$time <- done$digiEndTime - done$digiStartTime
#   ---- Get the shapefiles that should be done.
done$folder <- paste0('//lar-file-srv/Data/BTPD_2016/Digitizing/',done$Range,'/',done$Grid_ID)
rownames(done) <- NULL
nCells <- nrow(done)
checkCells <- data.frame(Grid_ID=rep(NA,nrow(done)),
Double=rep(NA,nrow(done)),
DatabaseName=rep(NA,nrow(done)),
FileName=rep(NA,nrow(done)))
for(i in 1:nCells){
if( done[i,]$digiDouble == 1 ){
checkCells[i,2] <- 1
#   ---- Get the items in the folder tied to this cell.
files <- dir(done[i,]$folder)
#   ---- See who actually digitized the cell.
fileCheckFirst <- substr(files,nchar(files) - 3,nchar(files)) == ".shp" & substr(files,1,1) == "p"
fileCheckSecond <- substr(files,nchar(files) - 3,nchar(files)) == ".shp" & substr(files,1,1) == "s"
fileFirstName <-  substr(files[fileCheckFirst],2,nchar(unlist(strsplit(files[fileCheckFirst],fixed=TRUE,"_"))[[1]]) - 1 + 1)
fileSecondName <-  substr(files[fileCheckSecond],2,nchar(unlist(strsplit(files[fileCheckSecond],fixed=TRUE,"_"))[[1]]) - 1 + 1)
#   ---- Compare to whom the cell was assigned.
checkCells[i,1] <- ifelse(length(fileFirstName) > 1 | length(fileSecondName) > 1,done[i,]$Grid_ID,"Ok")
if(checkCells[i,1] == "Ok"){   # if it gets through the first above check, do this second one.
checkCells[i,1] <- ifelse( (substr(fileFirstName,1,5) == substr(done[i,]$pFirstName,1,5) & substr(fileSecondName,1,5) == substr(done[i,]$sFirstName,1,5) ),
"Ok",done[i,]$Grid_ID)
}
} else {
checkCells[i,2] <- 0
#   ---- Get the items in the folder tied to this cell.
files <- dir(done[i,]$folder)
fileCheck <- substr(files,nchar(files) - 3,nchar(files)) == ".shp" & substr(files,1,1) == "p"
fileFirstName <- substr(files[fileCheck],2,nchar(unlist(strsplit(files[fileCheck],fixed=TRUE,"_"))[[1]]) - 1 + 1)
#   ---- Compare to whom the cell was assigned.
checkCells[i,1] <- ifelse(length(fileFirstName) > 1,done[i,]$Grid_ID,"Ok")
if(checkCells[i,1] == "Ok"){   # if it gets through the first above check, do this second one.
checkCells[i,1] <- ifelse(substr(fileFirstName,1,5) == substr(done[i,]$FirstName,1,5),"Ok",done[i,]$Grid_ID)
}
}
#   ---- If we have a discrepancy, record what the database shows.
if(!is.na(checkCells[i,1])){
checkCells[i,3] <- paste0(done[i,]$digiUserID," -- ",done[i,]$digiPartner,collapse=" -- ")
if( done[i,]$digiDouble == 1 ){
checkCells[i,4] <- paste(paste0(fileFirstName," -- ",fileSecondName),collapse=" -- ")
} else {
checkCells[i,4] <- paste(fileFirstName,collapse=" -- ")
}
}
}
fix <- checkCells[checkCells$Grid_ID != "Ok",]
fix <- fix[order(fix$Grid_ID),]
dim(fix)
fix
userID <- 100
getStatus("All")
#   ---- Check for a lock on table tblCellStatus.csv
lock <- file.exists("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Database/tblCellStatusLOCK.txt")
if(lock == TRUE){
stop("The function is currently locked;  try again in a minute.")
} else if(lock == FALSE){
#   ---- Lock the table tblCellStatus so that two users cannot update
#   ---- it at the same time.
lockdf <- data.frame(userID=userID)
write.table(lockdf,"//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Database/tblCellStatusLOCK.txt",row.names=FALSE)
Sys.sleep(15)
} else {
stop("Something is really wrong.\n")
}
userSummary()
getStatus("All")
8711/11101
sessionInfo()
require(rgeos)
.libPaths()
getStatus(873)
getStatus(546)
userSummary()
getSkippers()
getSkippers()
getStatus(873)
userSummary()
userSummary()
getStatus("All")
8772/11101
getSkippers()
getSkippers()
getStatus(873)
getStatus(296)
getStatus(546)
getStatus(912)
theNext <- "CO161510"
#   ---- Get folder structure.
tblFolders <- getFolderStatus()
theRange <- tblFolders[tblFolders$Grid_ID == theNext,]$Range
folder <- paste0("//LAR-FILE-SRV/Data/BTPD_2016/Digitizing/",theRange,"/",theNext)
files <- dir(folder)
#   ---- Find the primary and secondary shapefiles.
pShp <- sShp <- NA
pInd <- substr(files,1,1) == 'p' &
substr(files,nchar(files) - 3,nchar(files)) == ".shp" &
grepl("Towns",files,fixed=TRUE) &
!grepl("Copy",files,fixed=TRUE)
pShpC <- substr(files[pInd],1,nchar(files[pInd]) - 4)
sInd <- substr(files,1,1) == 's' &
substr(files,nchar(files) - 3,nchar(files)) == ".shp" &
grepl("Towns",files,fixed=TRUE) &
!grepl("Copy",files,fixed=TRUE)
sShpC <- substr(files[sInd],1,nchar(files[sInd]) - 4)
if( is.na(pShpC) | is.na(sShpC) | is.null(pShpC) | is.null(sShpC) ){
stop("The folder tied to the Grid_ID provided lacks the requisite 'p' and 's' 'Towns' shapefiles.  Investigate.")
}
#   ---- Need to see if we have shapefiles with no features. This happens often.
checkShp <- function(folder,shp){
if(is.null(tryCatch(readOGR(folder,shp,verbose=FALSE), warning = function(w) w)$message)){
shp2 <- tryCatch(readOGR(folder,shp,verbose=FALSE), warning = function(w) w)
} else if(tryCatch(readOGR(folder,shp,verbose=FALSE), warning = function(w) w)$message == "no features found" ){
shp2 <- 'no features found'
}
}
#   ---- Read in shapefiles, allowing for no features found.
pShp <- checkShp(folder,pShpC)
sShp <- checkShp(folder,sShpC)
#   ---- Check and see if there are errors that should be remedied via
#   ---- the town tool in Arc.
readCheckCellValidity <- function(Shp){
out <- tryCatch(
{
checkCellValidity(Shp,userID)
},
warning = function(cond){
return(1)
}
)
return(out)
}
#   ---- Apply the checking function, collecting any evidence of a warning.
checkApply <- function(shp){
if(class(get(paste0(substr(shp,1,1),'Shp'))) == "SpatialPolygonsDataFrame"){
lapply(shp,readCheckCellValidity)
#           #   ---- The function call to readCheckCellValidity gets rid of the lock.  Put it back for the
#           #   ---- function checkInCell.
#
#           #   ---- Check for a lock on table tblCellStatus.csv
#           lock <- grep("tblCellStatusLOCK",dir("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Database"),fixed=TRUE)
#           if(length(lock) > 0){
#             stop("The function is currently locked;  try again in a minute.")
#           } else {
#             #   ---- Lock the table tblCellStatus so that two users cannot update
#             #   ---- it at the same time.
#             lockdf <- data.frame(userID=userID)
#             write.table(lockdf,"//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Database/tblCellStatusLOCK.txt",row.names=FALSE)
#           }
} else {
cat(paste0("The check of ",shp," found no towns to check.  Be sure this is correct. If so, continue.\n"))
}
}
pShpCCheck <- checkApply(pShpC)
sShpCCheck <- checkApply(sShpC)
#   ---- Stop the wrapper function if there is a shapefile problem.
if( !is.null(pShpCCheck[[1]][1]) ){stop(paste0("Shapefile ",pShpC," has errors. Investigate."))}
if( !is.null(sShpCCheck[[1]][1]) ){stop(paste0("Shapefile ",sShpC," has errors. Investigate."))}
#   ---- Get names.
pName <- unlist(strsplit(pShpC,"_",fixed=TRUE)[[1]])[1]
pName <- substr(pName,2,nchar(pName))
sName <- unlist(strsplit(sShpC,"_",fixed=TRUE)[[1]])[1]
sName <- substr(sName,2,nchar(sName))
townShps <- vector("list",2)
townShps[[1]] <- pShp
townShps[[2]] <- sShp
#   ---- Given the list of neighboring towns, paste together
#   ---- into one nice shapefile; i.e., build reconciling set.
allShps <- NULL
if( !(class(townShps[[1]]) == "SpatialPolygonsDataFrame") ){
allShps <- townShps[[2]]
} else if( !(class(townShps[[2]]) == "SpatialPolygonsDataFrame") ){
allShps <- townShps[[1]]
} else {
for(j in 1:length(townShps)){
if(!is.null(townShps[[j]])){
nR <- length(slot(townShps[[j]],"polygons"))
if(j == 1){
uidR          <- 1
allShps       <- spChFIDs(townShps[[j]], as.character(uidR:(uidR + nR - 1)))
uidR          <- uidR + nR
} else {
townShps[[j]] <- spChFIDs(townShps[[j]], as.character(uidR:(uidR + nR - 1)))
uidR          <- uidR + nR
allShps       <- spRbind(allShps,townShps[[j]])
}
}
}
}
class(allShps) == "SpatialPolygonsDataFrame"
class(townShps[[1]])
townShps[[1]]
townShps[[2]]
require(rgdal)
#   ---- Get folder structure.
tblFolders <- getFolderStatus()
theRange <- tblFolders[tblFolders$Grid_ID == theNext,]$Range
folder <- paste0("//LAR-FILE-SRV/Data/BTPD_2016/Digitizing/",theRange,"/",theNext)
files <- dir(folder)
#   ---- Find the primary and secondary shapefiles.
pShp <- sShp <- NA
pInd <- substr(files,1,1) == 'p' &
substr(files,nchar(files) - 3,nchar(files)) == ".shp" &
grepl("Towns",files,fixed=TRUE) &
!grepl("Copy",files,fixed=TRUE)
pShpC <- substr(files[pInd],1,nchar(files[pInd]) - 4)
sInd <- substr(files,1,1) == 's' &
substr(files,nchar(files) - 3,nchar(files)) == ".shp" &
grepl("Towns",files,fixed=TRUE) &
!grepl("Copy",files,fixed=TRUE)
sShpC <- substr(files[sInd],1,nchar(files[sInd]) - 4)
if( is.na(pShpC) | is.na(sShpC) | is.null(pShpC) | is.null(sShpC) ){
stop("The folder tied to the Grid_ID provided lacks the requisite 'p' and 's' 'Towns' shapefiles.  Investigate.")
}
#   ---- Need to see if we have shapefiles with no features. This happens often.
checkShp <- function(folder,shp){
if(is.null(tryCatch(readOGR(folder,shp,verbose=FALSE), warning = function(w) w)$message)){
shp2 <- tryCatch(readOGR(folder,shp,verbose=FALSE), warning = function(w) w)
} else if(tryCatch(readOGR(folder,shp,verbose=FALSE), warning = function(w) w)$message == "no features found" ){
shp2 <- 'no features found'
}
}
#   ---- Read in shapefiles, allowing for no features found.
pShp <- checkShp(folder,pShpC)
sShp <- checkShp(folder,sShpC)
#   ---- Check and see if there are errors that should be remedied via
#   ---- the town tool in Arc.
readCheckCellValidity <- function(Shp){
out <- tryCatch(
{
checkCellValidity(Shp,userID)
},
warning = function(cond){
return(1)
}
)
return(out)
}
#   ---- Apply the checking function, collecting any evidence of a warning.
checkApply <- function(shp){
if(class(get(paste0(substr(shp,1,1),'Shp'))) == "SpatialPolygonsDataFrame"){
lapply(shp,readCheckCellValidity)
#           #   ---- The function call to readCheckCellValidity gets rid of the lock.  Put it back for the
#           #   ---- function checkInCell.
#
#           #   ---- Check for a lock on table tblCellStatus.csv
#           lock <- grep("tblCellStatusLOCK",dir("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Database"),fixed=TRUE)
#           if(length(lock) > 0){
#             stop("The function is currently locked;  try again in a minute.")
#           } else {
#             #   ---- Lock the table tblCellStatus so that two users cannot update
#             #   ---- it at the same time.
#             lockdf <- data.frame(userID=userID)
#             write.table(lockdf,"//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Database/tblCellStatusLOCK.txt",row.names=FALSE)
#           }
} else {
cat(paste0("The check of ",shp," found no towns to check.  Be sure this is correct. If so, continue.\n"))
}
}
pShpCCheck <- checkApply(pShpC)
sShpCCheck <- checkApply(sShpC)
#   ---- Stop the wrapper function if there is a shapefile problem.
if( !is.null(pShpCCheck[[1]][1]) ){stop(paste0("Shapefile ",pShpC," has errors. Investigate."))}
if( !is.null(sShpCCheck[[1]][1]) ){stop(paste0("Shapefile ",sShpC," has errors. Investigate."))}
#   ---- Get names.
pName <- unlist(strsplit(pShpC,"_",fixed=TRUE)[[1]])[1]
pName <- substr(pName,2,nchar(pName))
sName <- unlist(strsplit(sShpC,"_",fixed=TRUE)[[1]])[1]
sName <- substr(sName,2,nchar(sName))
townShps <- vector("list",2)
townShps[[1]] <- pShp
townShps[[2]] <- sShp
#   ---- Given the list of neighboring towns, paste together
#   ---- into one nice shapefile; i.e., build reconciling set.
allShps <- NULL
if( !(class(townShps[[1]]) == "SpatialPolygonsDataFrame") ){
allShps <- townShps[[2]]
} else if( !(class(townShps[[2]]) == "SpatialPolygonsDataFrame") ){
allShps <- townShps[[1]]
} else {
for(j in 1:length(townShps)){
if(!is.null(townShps[[j]])){
nR <- length(slot(townShps[[j]],"polygons"))
if(j == 1){
uidR          <- 1
allShps       <- spChFIDs(townShps[[j]], as.character(uidR:(uidR + nR - 1)))
uidR          <- uidR + nR
} else {
townShps[[j]] <- spChFIDs(townShps[[j]], as.character(uidR:(uidR + nR - 1)))
uidR          <- uidR + nR
allShps       <- spRbind(allShps,townShps[[j]])
}
}
}
}
pShpCCheck <- checkApply(pShpC)
pShp <- checkShp(folder,pShpC)
class(pShp)
folder
pShpC
readOGR(folder,shp,verbose=FALSE)
shp
shp <- pShpC
readOGR(folder,shp,verbose=FALSE)
ugh <- readOGR(folder,shp,verbose=FALSE)
plot(ugh)
readOGR(folder,shp,verbose=FALSE)
pShp <- checkShp(folder,pShpC)
pShp
plot(pShp)
pShp@data
#   ---- Read in shapefiles, allowing for no features found.
pShp <- checkShp(folder,pShpC)
sShp <- checkShp(folder,sShpC)
#   ---- Check and see if there are errors that should be remedied via
#   ---- the town tool in Arc.
readCheckCellValidity <- function(Shp){
out <- tryCatch(
{
checkCellValidity(Shp,userID)
},
warning = function(cond){
return(1)
}
)
return(out)
}
#   ---- Apply the checking function, collecting any evidence of a warning.
checkApply <- function(shp){
if(class(get(paste0(substr(shp,1,1),'Shp'))) == "SpatialPolygonsDataFrame"){
lapply(shp,readCheckCellValidity)
#           #   ---- The function call to readCheckCellValidity gets rid of the lock.  Put it back for the
#           #   ---- function checkInCell.
#
#           #   ---- Check for a lock on table tblCellStatus.csv
#           lock <- grep("tblCellStatusLOCK",dir("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Database"),fixed=TRUE)
#           if(length(lock) > 0){
#             stop("The function is currently locked;  try again in a minute.")
#           } else {
#             #   ---- Lock the table tblCellStatus so that two users cannot update
#             #   ---- it at the same time.
#             lockdf <- data.frame(userID=userID)
#             write.table(lockdf,"//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Database/tblCellStatusLOCK.txt",row.names=FALSE)
#           }
} else {
cat(paste0("The check of ",shp," found no towns to check.  Be sure this is correct. If so, continue.\n"))
}
}
pShpCCheck <- checkApply(pShpC)
sShpCCheck <- checkApply(sShpC)
#   ---- Stop the wrapper function if there is a shapefile problem.
if( !is.null(pShpCCheck[[1]][1]) ){stop(paste0("Shapefile ",pShpC," has errors. Investigate."))}
if( !is.null(sShpCCheck[[1]][1]) ){stop(paste0("Shapefile ",sShpC," has errors. Investigate."))}
#   ---- Get names.
pName <- unlist(strsplit(pShpC,"_",fixed=TRUE)[[1]])[1]
pName <- substr(pName,2,nchar(pName))
sName <- unlist(strsplit(sShpC,"_",fixed=TRUE)[[1]])[1]
sName <- substr(sName,2,nchar(sName))
townShps <- vector("list",2)
townShps[[1]] <- pShp
townShps[[2]] <- sShp
#   ---- Given the list of neighboring towns, paste together
#   ---- into one nice shapefile; i.e., build reconciling set.
allShps <- NULL
if( !(class(townShps[[1]]) == "SpatialPolygonsDataFrame") ){
allShps <- townShps[[2]]
} else if( !(class(townShps[[2]]) == "SpatialPolygonsDataFrame") ){
allShps <- townShps[[1]]
} else {
for(j in 1:length(townShps)){
if(!is.null(townShps[[j]])){
nR <- length(slot(townShps[[j]],"polygons"))
if(j == 1){
uidR          <- 1
allShps       <- spChFIDs(townShps[[j]], as.character(uidR:(uidR + nR - 1)))
uidR          <- uidR + nR
} else {
townShps[[j]] <- spChFIDs(townShps[[j]], as.character(uidR:(uidR + nR - 1)))
uidR          <- uidR + nR
allShps       <- spRbind(allShps,townShps[[j]])
}
}
}
}
class(allShps) == "SpatialPolygonsDataFrame"
allShps@data$Recon_T_ID <- rep("",nrow(allShps))
allShps@data$new1 <- rep('x',nrow(allShps))
names(allShps@data)[names(allShps@data) == "new1"] <- paste0(substr(pName,1,5),"_T_ID")
allShps@data$new2 <- rep('x',nrow(allShps))
names(allShps@data)[names(allShps@data) == "new2"] <- paste0(substr(sName,1,5),"_T_ID")
allShps@data$Recon_DIE <- rep('',nrow(allShps))
allShps@data$Town_ID <- NULL
dim(allShps)
plot(allShps)
writeOGR(allShps,folder,paste0("reconciling_Towns_",theNext),overwrite_layer=TRUE,driver="ESRI Shapefile",verbose=FALSE)
getSkippers()
