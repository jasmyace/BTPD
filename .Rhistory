allShps <- NULL
first <- 0
triggered <- 0
for(j in 1:length(townShps)){
if( class(townShps[[j]]) == "SpatialPolygonsDataFrame" ){
nR <- length(slot(townShps[[j]],"polygons"))
if(triggered == 0){
first <- 1
}
if(first == 1){
uidR          <- 1
allShps       <- spChFIDs(townShps[[j]], as.character(uidR:(uidR + nR - 1)))
uidR          <- uidR + nR
triggered     <- 1
first         <- 0
} else {
townShps[[j]] <- spChFIDs(townShps[[j]], as.character(uidR:(uidR + nR - 1)))
uidR          <- uidR + nR
allShps       <- spRbind(allShps,townShps[[j]])
}
}
}
#   ---- Polygon allShps contains all the polygons of towns drawn
#   ---- by neighboring cells in the buffer of the cell of interest,
#   ---- excluding any towns with a higher BAS number.  Save it.
otherTowns <- 0
#otherTownsp <- 0
if(!is.null(allShps)){  # nrow(allShps@data) > 0
writeOGR(allShps,paste0("//lar-file-srv/Data/BTPD_2016/Digitizing/",theFolder$Range,"/",theNext),paste0("LocalTowns_",theNext),overwrite_layer=TRUE,driver="ESRI Shapefile")
#otherTownsp <- gArea()
otherTowns <- 1
}
localGrid <- as(shpGID,"SpatialLinesDataFrame")
localGrid <- spTransform(localGrid,CRS(projAEAc))
#   ---- Determine length in meters of one cell; i.e., transect length.
cellUnit <- 3218.694
#   ---- Make a mini-grid shapefile of the buffer region for placement
#   ---- into the theNext folder.  Currently assumes a 3x3 big local grid.
r <- raster(extent(gBuffer(shpGID,width=cellUnit)),nrow=15,ncol=15,crs=shpBuf@proj4string)
#r <- raster(extent(shpBuf@bbox),nrow=15,ncol=15,crs=shpBuf@proj4string)
r[] <- 1:ncell(r)
miniGrid <- as(r, "SpatialPolygonsDataFrame")
miniGrid <- as(miniGrid,"SpatialLinesDataFrame")
miniGrid <- spTransform(miniGrid,CRS(projAEAc))
cat("Preparation complete. ")
cat(paste0("Your new cell to digitize is ",theNext,".\n"))
if( otherTowns == 1){
cat("--- *** ---> Previously digitized towns are in your buffer.  These areas are off-limits for digitizing. <--- *** ---\n")
} else {
cat(paste0("No towns found within the buffering radius of cell ",theNext,". All areas open for digitizing.\n"))
}
found <- TRUE
#   ---- Make an easy map, so people have an idea of where they're going.
getStatus("All",plotOnly=TRUE)
AddHoleToPolygon <-function(poly,hole){
# poly <- outCircle
# hole <- inCircle
# invert the coordinates for Polygons to flag it as a hole
coordsHole <-  hole@polygons[[1]]@Polygons[[1]]@coords
newHole <- Polygon(coordsHole,hole=TRUE)
# punch the hole in the main poly
listPol <- poly@polygons[[1]]@Polygons
listPol[[length(listPol)+1]] <- newHole
punch <- Polygons(listPol,poly@polygons[[1]]@ID)
# make the polygon a SpatialPolygonsDataFrame as the entry
new <- SpatialPolygons(list(punch),proj4string=poly@proj4string)
#new <- SpatialPolygonsDataFrame(new,data=as(poly,"data.frame"))
return(new)
}
plot(shpGID,add=TRUE,col="#d7191c",border="white")
outCircle <- gBuffer(gCentroid(shpGID),byid=TRUE,width=12000)
inCircle <- gBuffer(gCentroid(shpGID),byid=TRUE,width=9000)
ring <- AddHoleToPolygon(outCircle,inCircle)
plot(ring,add=TRUE,col="red",border="red")
is.null(allShps)
mtext(side=3,line=-0.75,"Your newly checked-out cell is circled in red.")
mtext(side=1,line=1.00,"Be wary of possible towns in your new cell's buffer.",col="red")
mtext(side=1,line=0,"Be wary of possible towns in your new cell's buffer.",col="red")
mtext(side=1,line=0.25,"Be wary of possible towns in your new cell's buffer.",col="red")
mtext(side=1,line=-0.25,"Be wary of possible towns in your new cell's buffer.",col="red")
mtext(side=1,line=-0.5,"Be wary of possible towns in your new cell's buffer.",col="red")
#   ---- Make an easy map, so people have an idea of where they're going.
getStatus("All",plotOnly=TRUE)
#   ---- Add a red ring to easily pick out the new cell.  Accessed 5/24/2016.
#   ---- http://stackoverflow.com/questions/29624895/how-to-add-a-hole-to-a-polygon-within-a-spatialpolygonsdataframe
AddHoleToPolygon <-function(poly,hole){
# poly <- outCircle
# hole <- inCircle
# invert the coordinates for Polygons to flag it as a hole
coordsHole <-  hole@polygons[[1]]@Polygons[[1]]@coords
newHole <- Polygon(coordsHole,hole=TRUE)
# punch the hole in the main poly
listPol <- poly@polygons[[1]]@Polygons
listPol[[length(listPol)+1]] <- newHole
punch <- Polygons(listPol,poly@polygons[[1]]@ID)
# make the polygon a SpatialPolygonsDataFrame as the entry
new <- SpatialPolygons(list(punch),proj4string=poly@proj4string)
#new <- SpatialPolygonsDataFrame(new,data=as(poly,"data.frame"))
return(new)
}
if(double == 0){
plot(shpGID,add=TRUE,col="#d7191c",border="white")
} else {
#   ---- We have a double cell.  Color it for the userID calling the check-out.
if( assignInfo$userIDAssign == "Secondary"){
plot(shpGID,add=TRUE,col="#ffffbf",border="white")
} else {
plot(shpGID,add=TRUE,col="#fdae61",border="white")
}
}
outCircle <- gBuffer(gCentroid(shpGID),byid=TRUE,width=12000)
inCircle <- gBuffer(gCentroid(shpGID),byid=TRUE,width=9000)
ring <- AddHoleToPolygon(outCircle,inCircle)
plot(ring,add=TRUE,col="red",border="red")
mtext(side=3,line=-0.75,"Your newly checked-out cell is circled in red.")
mtext(side=1,line=-0.5,"Be wary of possible towns in your new cell's buffer.",col="red")
mtext(side=1,line=-0.75,"Be wary of possible towns in your new cell's buffer.",col="red")
#   ---- Make an easy map, so people have an idea of where they're going.
getStatus("All",plotOnly=TRUE)
#   ---- Add a red ring to easily pick out the new cell.  Accessed 5/24/2016.
#   ---- http://stackoverflow.com/questions/29624895/how-to-add-a-hole-to-a-polygon-within-a-spatialpolygonsdataframe
AddHoleToPolygon <-function(poly,hole){
# poly <- outCircle
# hole <- inCircle
# invert the coordinates for Polygons to flag it as a hole
coordsHole <-  hole@polygons[[1]]@Polygons[[1]]@coords
newHole <- Polygon(coordsHole,hole=TRUE)
# punch the hole in the main poly
listPol <- poly@polygons[[1]]@Polygons
listPol[[length(listPol)+1]] <- newHole
punch <- Polygons(listPol,poly@polygons[[1]]@ID)
# make the polygon a SpatialPolygonsDataFrame as the entry
new <- SpatialPolygons(list(punch),proj4string=poly@proj4string)
#new <- SpatialPolygonsDataFrame(new,data=as(poly,"data.frame"))
return(new)
}
if(double == 0){
plot(shpGID,add=TRUE,col="#d7191c",border="white")
} else {
#   ---- We have a double cell.  Color it for the userID calling the check-out.
if( assignInfo$userIDAssign == "Secondary"){
plot(shpGID,add=TRUE,col="#ffffbf",border="white")
} else {
plot(shpGID,add=TRUE,col="#fdae61",border="white")
}
}
outCircle <- gBuffer(gCentroid(shpGID),byid=TRUE,width=12000)
inCircle <- gBuffer(gCentroid(shpGID),byid=TRUE,width=9000)
ring <- AddHoleToPolygon(outCircle,inCircle)
plot(ring,add=TRUE,col="red",border="red")
mtext(side=3,line=-0.75,"Your newly checked-out cell is circled in red.")
mtext(side=1,line=-0.75,"Be wary of possible towns in your new cell's buffer.",col="red")
mtext(side=1,line=-1.00,"Be wary of possible towns in your new cell's buffer.",col="red")
#   ---- Make an easy map, so people have an idea of where they're going.
getStatus("All",plotOnly=TRUE)
#   ---- Add a red ring to easily pick out the new cell.  Accessed 5/24/2016.
#   ---- http://stackoverflow.com/questions/29624895/how-to-add-a-hole-to-a-polygon-within-a-spatialpolygonsdataframe
AddHoleToPolygon <-function(poly,hole){
# poly <- outCircle
# hole <- inCircle
# invert the coordinates for Polygons to flag it as a hole
coordsHole <-  hole@polygons[[1]]@Polygons[[1]]@coords
newHole <- Polygon(coordsHole,hole=TRUE)
# punch the hole in the main poly
listPol <- poly@polygons[[1]]@Polygons
listPol[[length(listPol)+1]] <- newHole
punch <- Polygons(listPol,poly@polygons[[1]]@ID)
# make the polygon a SpatialPolygonsDataFrame as the entry
new <- SpatialPolygons(list(punch),proj4string=poly@proj4string)
#new <- SpatialPolygonsDataFrame(new,data=as(poly,"data.frame"))
return(new)
}
if(double == 0){
plot(shpGID,add=TRUE,col="#d7191c",border="white")
} else {
#   ---- We have a double cell.  Color it for the userID calling the check-out.
if( assignInfo$userIDAssign == "Secondary"){
plot(shpGID,add=TRUE,col="#ffffbf",border="white")
} else {
plot(shpGID,add=TRUE,col="#fdae61",border="white")
}
}
outCircle <- gBuffer(gCentroid(shpGID),byid=TRUE,width=12000)
inCircle <- gBuffer(gCentroid(shpGID),byid=TRUE,width=9000)
ring <- AddHoleToPolygon(outCircle,inCircle)
plot(ring,add=TRUE,col="red",border="red")
#   ---- Towns in buffer.
mtext(side=3,line=-0.75,"Your newly checked-out cell is circled in red.")
mtext(side=1,line=-1.00,"Be wary of possible towns in your new cell's buffer.",col="red")
shp <- CO
load(file="//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Overnights/Data/Overnights.RData")
shp <- CO
#   ---- Get folder structure.
tblFolders <- getFolderStatus()
#   ---- Get the current list of who has what.
assign <- getCellStatus()
#   ---- Get users.
tblNames <- checkUser(userID=100)
#   ---- Get sampling.
tblRanks <- getRankStatus()
tblRanks <- tblRanks[order(tblRanks$sampleID),]
#   ---- Calculate elapsed time spent while digitizing.
done <- assign[assign$doneStatus == 1,c('Grid_ID','digiUserID','digiPartner','digiDouble','digiStartTime','digiEndTime','jErrStatus')]
done$digiStartTime <- as.POSIXct(done$digiStartTime,format="%m/%d/%Y %H:%M",tz="America/Denver")
done$digiEndTime <- as.POSIXct(done$digiEndTime,format="%m/%d/%Y %H:%M",tz="America/Denver")
done$time <- as.numeric(done$digiEndTime - done$digiStartTime) / 60
done <- done[done$jErrStatus == 0,]
#   ---- Count the number of towns per cell.
towns <- data.frame(nTowns=tapply(shp@data$Town_ID,factor(shp@data$Grid_ID),function(x) length(x)))
towns$Grid_ID <- rownames(towns)
rownames(towns) <- NULL
#   ---- Put together times and town counts.
done <- merge(done,towns,by=c('Grid_ID'),all.x=TRUE)
done$nTowns[is.na(done$nTowns)] <- 0
#   ---- Focus on singly digitized.
singly <- done[done$digiDouble == 0,]
#   ---- Calculate mean singly number of towns.
avgTowns <- mean(singly$nTowns)
#   ---- Calculate time as a function of number of towns.
avgMinTown <- data.frame(avgMin=tapply(as.numeric(singly$time),factor(singly$nTowns),function(x) mean(x)))
avgMinTown$nTowns <- as.numeric(rownames(avgMinTown))
rownames(avgMinTown) <- NULL
#   ---- Make distribution of town counts.
counts=hist(singly$nTowns,plot=FALSE,breaks=seq(0,max(singly$nTowns) + 1,1),right=FALSE)$counts
nTowns=hist(singly$nTowns,plot=FALSE,breaks=seq(0,max(singly$nTowns) + 1,1),right=FALSE)$breaks
townDist <- data.frame(counts=counts,nTowns=nTowns[1:length(counts)])
#   ---- Calculate proportion of cells having the town distribution.
townCounts <- merge(avgMinTown,townDist,by=c('nTowns'),all.x=TRUE,all.y=TRUE)
townCounts$prop <- townCounts$counts / sum(townCounts$counts)
#   ---- Find the remaining number of cells, and estimate time to completion.
nLeft <- nrow(assign) - nrow(done)
townCounts$propLeft <- nLeft*townCounts$prop
townCounts$totMins <- townCounts$propLeft*townCounts$avgMin
townCounts$totMins[is.na(townCounts$totMins)] <- 0
#   ---- Method 1:
m1TotMins <- mean(as.numeric(singly$time)) * nLeft
m1TotHours <- m1TotMins / 60
totHours <- sum(townCounts$totMins) / 60
plot(factor(singly$nTowns),as.numeric(singly$time))
#   ---- Person-based.  How many cells are people doing in a work day?
singly <- done[done$digiDouble == 0,]
#   ---- Note that I build each day by 24 hours.  This won't work if we straddle a time change.
dayLabels <- unique(strftime(as.POSIXlt(singly$digiEndTime),format="%D"))
dayLabels <- c(dayLabels[order(dayLabels)],"Total")
singly$jDay <- as.numeric(floor(julian(as.POSIXlt(singly$digiEndTime),origin=as.POSIXct("2016-05-21",tz="America/Denver"))) + 1)
counts <- as.matrix(table(singly$digiUserID,singly$jDay))
counts <- cbind(counts,rowSums(counts))
counts <- rbind(counts,colSums(counts))
colnames(counts) <- dayLabels
dayTotals <- counts[nrow(counts),]
dayTotals
#   ---- Check if Jason is turned off or on.
p1 <- getPhaseData(1,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p2 <- getPhaseData(2,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p3 <- getPhaseData(3,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p4 <- getPhaseData(4,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
#p5 <- getPhaseData(5,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p6 <- getPhaseData(6,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p <- rbind(p1,p2,p3,p4,p6)
p[is.na(p)] <- 0
p$totAmt <- as.numeric(gsub(",", "", as.character(p$totAmt)))
q1 <- summMetric(p,'regHours')
q2 <- summMetric(p,'otHours')
q3 <- summMetric(p,'totHours')
q4 <- summMetric(p,'totAmt')
fiveDayCellMean <- projGraph(endDate="2016/09/01",multi=1.00)
fiveDayCellMean <- projGraph(endDate="2016/09/15",multi=1.00)
fiveDayCellMean <- projGraph(endDate="2016/10/01",multi=1.00)
#   ---- Assume a 119 cells per day over 6 digitizers.  This leads to one digitizer
#   ---- doing 119/6 cells per day, or k digitizers doing a multiple of that.
perDigi <- fiveDayCellMean / 6
k <- 1
Multi <- (fiveDayCellMean + k*perDigi) / fiveDayCellMean
projGraph(endDate="2016/09/01",multi=Multi)
projGraph(endDate="2016/09/15",multi=Multi)
projGraph(endDate="2016/10/01",multi=Multi)
#   ---- Assume two additional digitizers.
k <- 2
Multi <- (fiveDayCellMean + k*perDigi) / fiveDayCellMean
projGraph(endDate="2016/09/01",multi=Multi)
projGraph(endDate="2016/09/15",multi=Multi)
projGraph(endDate="2016/10/01",multi=Multi)
#   ---- Budget projections.
digiDF <- data.frame(nDigi=dayTotals)
digiDF$asDate <- as.Date(rownames(digiDF),format="%m/%d/%y")
rownames(digiDF) <- NULL
digiDF <- merge(q4,digiDF,by=c('asDate'),all.x=TRUE)
digiDF <- digiDF[digiDF$asDate <= "2016-06-18",]
digiDF <- digiDF[order(digiDF$nDigi),]
digiDF <- digiDF[!is.na(digiDF$nDigi),]
x <- digiDF$nDigi[!is.na(digiDF$nDigi)]
y <- digiDF$phase2totAmt[!is.na(digiDF$nDigi)]
model <- lm(y ~ x)
b0 <- coefficients(model)[1]
b1 <- coefficients(model)[2]
p <- model$fitted.values
plot(x,y,xlim=c(0,max(x)),ylim=c(0,max(y)),xlab="N Cells Digitized",ylab="Dollar Amount",main="per-Day Digitizing Cost as a Function of Cells Completed")
par(new=TRUE)
plot(x,p,xlim=c(0,max(x)),ylim=c(0,max(y)),xaxt="n",yaxt="n",xlab="",ylab="",type="l")
cellsComplete <- 1987
cellsRemain <- 11101 - 1987
remainingDigi <- cellsRemain * b1
source("//lar-file-srv/Data/BTPD_2016/Analysis/pDog/R/projGraph.R")
source("//lar-file-srv/Data/BTPD_2016/Analysis/pDog/R/summMetric.R")
source("//lar-file-srv/Data/BTPD_2016/Analysis/pDog/R/getPhaseData.R")
source("//lar-file-srv/Data/BTPD_2016/Analysis/Overnights/Programs/projGraph.R")
source("//lar-file-srv/Data/BTPD_2016/Analysis/Overnights/Programs/summMetric.R")
source("//lar-file-srv/Data/BTPD_2016/Analysis/Overnights/Programs/getPhaseData.R")
#   ---- Check if Jason is turned off or on.
p1 <- getPhaseData(1,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p2 <- getPhaseData(2,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p3 <- getPhaseData(3,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p4 <- getPhaseData(4,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
#p5 <- getPhaseData(5,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p6 <- getPhaseData(6,labrDate="062016",labrStem="//LAR-FILE-SRV/Data/BTPD_2016/Project Management/export")
p <- rbind(p1,p2,p3,p4,p6)
p[is.na(p)] <- 0
p$totAmt <- as.numeric(gsub(",", "", as.character(p$totAmt)))
q1 <- summMetric(p,'regHours')
q2 <- summMetric(p,'otHours')
q3 <- summMetric(p,'totHours')
q4 <- summMetric(p,'totAmt')
fiveDayCellMean <- projGraph(endDate="2016/09/01",multi=1.00)
fiveDayCellMean <- projGraph(endDate="2016/09/15",multi=1.00)
fiveDayCellMean <- projGraph(endDate="2016/10/01",multi=1.00)
#   ---- Assume a 119 cells per day over 6 digitizers.  This leads to one digitizer
#   ---- doing 119/6 cells per day, or k digitizers doing a multiple of that.
perDigi <- fiveDayCellMean / 6
k <- 1
Multi <- (fiveDayCellMean + k*perDigi) / fiveDayCellMean
projGraph(endDate="2016/09/01",multi=Multi)
dev.off()
projGraph(endDate="2016/09/01",multi=Multi)
digiDF <- data.frame(nDigi=dayTotals)
digiDF$asDate <- as.Date(rownames(digiDF),format="%m/%d/%y")
rownames(digiDF) <- NULL
digiDF <- merge(q4,digiDF,by=c('asDate'),all.x=TRUE)
digiDF <- digiDF[digiDF$asDate <= "2016-06-18",]
digiDF <- digiDF[order(digiDF$nDigi),]
digiDF <- digiDF[!is.na(digiDF$nDigi),]
x <- digiDF$nDigi[!is.na(digiDF$nDigi)]
y <- digiDF$phase2totAmt[!is.na(digiDF$nDigi)]
model <- lm(y ~ x)
b0 <- coefficients(model)[1]
b1 <- coefficients(model)[2]
p <- model$fitted.values
plot(x,y,xlim=c(0,max(x)),ylim=c(0,max(y)),xlab="N Cells Digitized",ylab="Dollar Amount",main="per-Day Digitizing Cost as a Function of Cells Completed")
par(new=TRUE)
plot(x,p,xlim=c(0,max(x)),ylim=c(0,max(y)),xaxt="n",yaxt="n",xlab="",ylab="",type="l")
cellsComplete <- 1987
cellsRemain <- 11101 - 1987
remainingDigi <- cellsRemain * b1
remainingDigi
#   ---- Given the cells that have been examined, find those that have a town to contribute towards analyses.
cellsWithData <- unique(CO@data$sampleID)
nCellsDigi <- length(cellsWithData)
#   ---- Loop through folders to be made.
for(i in 1:nCellsDigi){
#   ---- Make individual folders.
nightDir <- paste0("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Overnights/Results/Nightly/",cellsWithData[i])
ifelse(!dir.exists(file.path(nightDir)), dir.create(file.path(nightDir),showWarnings=TRUE,recursive=TRUE), FALSE)
#   ---- Make individual folders: FMP with ...
FMP1Dir <- paste0("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Overnights/Results/Nightly/",cellsWithData[i],"/FMP1")
ifelse(!dir.exists(file.path(FMP1Dir)), dir.create(file.path(FMP1Dir),showWarnings=TRUE,recursive=TRUE), FALSE)
#   ---- Make individual folders: FMP with ...
FMP2Dir <- paste0("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Overnights/Results/Nightly/",cellsWithData[i],"/FMP2")
ifelse(!dir.exists(file.path(FMP2Dir)), dir.create(file.path(FMP2Dir),showWarnings=TRUE,recursive=TRUE), FALSE)
#   ---- Make individual folders: FMP with ...
FMP3Dir <- paste0("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Overnights/Results/Nightly/",cellsWithData[i],"/FMP3")
ifelse(!dir.exists(file.path(FMP3Dir)), dir.create(file.path(FMP3Dir),showWarnings=TRUE,recursive=TRUE), FALSE)
#   ---- Make individual folders:  Doublies for Centroids.
Dbl1Dir <- paste0("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Overnights/Results/Nightly/",cellsWithData[i],"/Dbl1")
ifelse(!dir.exists(file.path(Dbl1Dir)), dir.create(file.path(Dbl1Dir),showWarnings=TRUE,recursive=TRUE), FALSE)
#   ---- Make individual folders:  Doublies for Clippings.
Dbl2Dir <- paste0("//LAR-FILE-SRV/Data/BTPD_2016/Analysis/Overnights/Results/Nightly/",cellsWithData[i],"/Dbl2")
ifelse(!dir.exists(file.path(Dbl2Dir)), dir.create(file.path(Dbl2Dir),showWarnings=TRUE,recursive=TRUE), FALSE)
}
#   ---- Build up a samps data frame containing sampling information.
state <- "CO"
grid_N <- 11101
grid_Sampled_D <- 1136
grid_Sampled_S <- 9965
samps <- data.frame(State=state,Grid_N=grid_N,Grid_Sampled_D=grid_Sampled_D,Grid_Sampled_S=grid_Sampled_S,Type="Recon")
theFolders <- getFolderStatus()
ranks <- getRankStatus()
users <- checkUser(100)
#   ---- Estimate the doubles per each new cell added to the mix.
CODblTowns <- CO[CO@data$double == 1,]
CODblGrids <- grid[grid@data$dblSamp == 1,]
trigger <- 0
cellsWithDoubles <- unique(CODoubles@data$sampleID)
nCellsWithDoubles <- length(cellsWithDoubles)
for(i in 1:nCellsWithDoubles){
#   ---- Check if we've calculated doubles up to this point (cell).
#   ---- Note that I use Dbl1 for this.
fileSave <- paste0("//lar-file-srv/Data/BTPD_2016/Analysis/Overnights/Results/Nightly/",cellsWithData[i],"/Dbl1")
if( !(file.exists(paste0(fileSave,"/Dbl1 Calculated=Yes.txt"))) & trigger == 0 ){
trigger <- 1
theFirstCell <- cellsWithDoubles[i]
}
}
source("//lar-file-srv/Data/BTPD_2016/Analysis/Overnights/Programs/doubleSampleEstimation.R")
source("//lar-file-srv/Data/BTPD_2016/Analysis/Overnights/Programs/biasCorrectedBootstrap.R")
b1
p <- rbind(p1,p2,p3,p4,p6)
p[is.na(p)] <- 0
p$totAmt <- as.numeric(gsub(",", "", as.character(p$totAmt)))
q1 <- summMetric(p,'regHours')
q2 <- summMetric(p,'otHours')
q3 <- summMetric(p,'totHours')
q4 <- summMetric(p,'totAmt')
fiveDayCellMean <- projGraph(endDate="2016/09/01",multi=1.00)
fiveDayCellMean <- projGraph(endDate="2016/09/15",multi=1.00)
fiveDayCellMean <- projGraph(endDate="2016/10/01",multi=1.00)
#   ---- Assume a 119 cells per day over 6 digitizers.  This leads to one digitizer
#   ---- doing 119/6 cells per day, or k digitizers doing a multiple of that.
perDigi <- fiveDayCellMean / 6
k <- 1
Multi <- (fiveDayCellMean + k*perDigi) / fiveDayCellMean
projGraph(endDate="2016/09/01",multi=Multi)
p <- rbind(p1,p2,p3,p4,p6)
p[is.na(p)] <- 0
p$totAmt <- as.numeric(gsub(",", "", as.character(p$totAmt)))
q1 <- summMetric(p,'regHours')
q2 <- summMetric(p,'otHours')
q3 <- summMetric(p,'totHours')
q4 <- summMetric(p,'totAmt')
fiveDayCellMean <- projGraph(endDate="2016/09/01",multi=1.00)
fiveDayCellMean <- projGraph(endDate="2016/09/15",multi=1.00)
fiveDayCellMean <- projGraph(endDate="2016/10/01",multi=1.00)
#   ---- Assume a 119 cells per day over 6 digitizers.  This leads to one digitizer
#   ---- doing 119/6 cells per day, or k digitizers doing a multiple of that.
perDigi <- fiveDayCellMean / 6
k <- 1
Multi <- (fiveDayCellMean + k*perDigi) / fiveDayCellMean
projGraph(endDate="2016/09/01",multi=Multi)
projGraph(endDate="2016/09/15",multi=Multi)
projGraph(endDate="2016/10/01",multi=Multi)
#   ---- Assume two additional digitizers.
k <- 2
Multi <- (fiveDayCellMean + k*perDigi) / fiveDayCellMean
projGraph(endDate="2016/09/01",multi=Multi)
projGraph(endDate="2016/09/15",multi=Multi)
projGraph(endDate="2016/10/01",multi=Multi)
dayTotals
counts <- as.matrix(table(singly$digiUserID,singly$jDay))
counts <- cbind(counts,rowSums(counts))
counts <- rbind(counts,colSums(counts))
colnames(counts) <- dayLabels
dayTotals <- counts[nrow(counts),]
dayTotals
#   ---- Get folder structure.
tblFolders <- getFolderStatus()
#   ---- Get the current list of who has what.
assign <- getCellStatus()
#   ---- Get users.
tblNames <- checkUser(userID=100)
#   ---- Get sampling.
tblRanks <- getRankStatus()
tblRanks <- tblRanks[order(tblRanks$sampleID),]
#   ---- Calculate elapsed time spent while digitizing.
done <- assign[assign$doneStatus == 1,c('Grid_ID','digiUserID','digiPartner','digiDouble','digiStartTime','digiEndTime','jErrStatus')]
done$digiStartTime <- as.POSIXct(done$digiStartTime,format="%m/%d/%Y %H:%M",tz="America/Denver")
done$digiEndTime <- as.POSIXct(done$digiEndTime,format="%m/%d/%Y %H:%M",tz="America/Denver")
done$time <- as.numeric(done$digiEndTime - done$digiStartTime) / 60
done <- done[done$jErrStatus == 0,]
#   ---- Count the number of towns per cell.
towns <- data.frame(nTowns=tapply(shp@data$Town_ID,factor(shp@data$Grid_ID),function(x) length(x)))
towns$Grid_ID <- rownames(towns)
rownames(towns) <- NULL
#   ---- Put together times and town counts.
done <- merge(done,towns,by=c('Grid_ID'),all.x=TRUE)
done$nTowns[is.na(done$nTowns)] <- 0
#   ---- Focus on singly digitized.
singly <- done[done$digiDouble == 0,]
#   ---- Calculate mean singly number of towns.
avgTowns <- mean(singly$nTowns)
#   ---- Calculate time as a function of number of towns.
avgMinTown <- data.frame(avgMin=tapply(as.numeric(singly$time),factor(singly$nTowns),function(x) mean(x)))
avgMinTown$nTowns <- as.numeric(rownames(avgMinTown))
rownames(avgMinTown) <- NULL
#   ---- Make distribution of town counts.
counts=hist(singly$nTowns,plot=FALSE,breaks=seq(0,max(singly$nTowns) + 1,1),right=FALSE)$counts
nTowns=hist(singly$nTowns,plot=FALSE,breaks=seq(0,max(singly$nTowns) + 1,1),right=FALSE)$breaks
townDist <- data.frame(counts=counts,nTowns=nTowns[1:length(counts)])
#   ---- Calculate proportion of cells having the town distribution.
townCounts <- merge(avgMinTown,townDist,by=c('nTowns'),all.x=TRUE,all.y=TRUE)
townCounts$prop <- townCounts$counts / sum(townCounts$counts)
#   ---- Find the remaining number of cells, and estimate time to completion.
nLeft <- nrow(assign) - nrow(done)
townCounts$propLeft <- nLeft*townCounts$prop
townCounts$totMins <- townCounts$propLeft*townCounts$avgMin
townCounts$totMins[is.na(townCounts$totMins)] <- 0
#   ---- Method 1:
m1TotMins <- mean(as.numeric(singly$time)) * nLeft
m1TotHours <- m1TotMins / 60
totHours <- sum(townCounts$totMins) / 60
plot(factor(singly$nTowns),as.numeric(singly$time))
#   ---- Person-based.  How many cells are people doing in a work day?
singly <- done[done$digiDouble == 0,]
#   ---- Note that I build each day by 24 hours.  This won't work if we straddle a time change.
dayLabels <- unique(strftime(as.POSIXlt(singly$digiEndTime),format="%D"))
dayLabels <- c(dayLabels[order(dayLabels)],"Total")
singly$jDay <- as.numeric(floor(julian(as.POSIXlt(singly$digiEndTime),origin=as.POSIXct("2016-05-21",tz="America/Denver"))) + 1)
counts <- as.matrix(table(singly$digiUserID,singly$jDay))
counts <- cbind(counts,rowSums(counts))
counts <- rbind(counts,colSums(counts))
colnames(counts) <- dayLabels
dayTotals <- counts[nrow(counts),]
dayTotals
counts
p2
